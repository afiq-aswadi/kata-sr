[kata]
name = "extract_attention_patterns"
category = "interpretability"
base_difficulty = 2
description = """
Extract attention patterns from a transformer model's cache.

Access the post-softmax attention weights from a specific layer using
TransformerLens cache interface.
"""
dependencies = ["transformerlens_hooks"]
tags = ["attention", "interpretability"]
