[kata]
name = "attention_patterns"
category = "interpretability"
base_difficulty = 3
description = """
Analyze and visualize attention patterns in transformer models using TransformerLens.

Learn to extract attention weights, identify important heads, and understand information
flow through attention layers. Extract patterns from cache, compute statistics like entropy,
and ablate specific heads to measure their impact.

Key concepts: attention pattern extraction, visualization, entropy, head ablation, induction heads
"""
dependencies = ["transformerlens_hooks"]
